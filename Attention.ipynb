{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm\n",
        "\n",
        "* Compute the Query, Key and Value from the Input\n",
        "* Calculate the Q*K^T\n",
        "* Scale the Scores Q*K^T/sqrt(dimension vector)\n",
        "* Apply Softmax\n",
        "* Multiply with Value Matrix.\n",
        "\n",
        "#### Why Scaling Factor (sqrt(dim-vector))\n",
        "It is to make sure that the dot products dont become too large which would push the softmax function into regions of small gradients.\n",
        "\n",
        "Without scaling, the dimensions (dk) shall grow and thereby dot product will grow in magnitude making softmax peaked out and gradient will become very small.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n"
      ],
      "metadata": {
        "id": "uYBFdNQ3JA73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx-MQ0G9IUk5"
      },
      "outputs": [],
      "source": [
        "# Attention creates Context Aware Embeddings\n",
        "import numpy as np\n",
        "\n",
        "def self_attention(input_embeddings):\n",
        "  '''Takes Input Embedding and generates Attention Scores'''\n",
        "  '''Input Embeddings are basic representation of the text\n",
        "  They do not understand the semantics in detail. However,\n",
        "  our objective of LLM is to make sure that the correct word\n",
        "  gets the correct importance. So we will have to calculate the\n",
        "  Importance which is nothing but Attention. So, attention scores\n",
        "  or the embeddings that will generate after Attention processing\n",
        "  are called Context Aware Embeddings'''\n",
        "\n",
        "  sentence_length, embedding_dim = input_embeddings.shape\n",
        "  '''Define the Learnable Weight Matrices for Query, Key and Value'''\n",
        "  '''Initialise the Weight Matrices with random values'''\n",
        "  np.random.seed(42) # reproduce the same nos again...\n",
        "  w_q = np.random.randn(embedding_dim, embedding_dim)\n",
        "  w_k = np.random.randn(embedding_dim, embedding_dim)\n",
        "  w_v = np.random.randn(embedding_dim, embedding_dim)\n",
        "\n",
        "  '''Calculate the dot product of Query, Key and Value Matrices'''\n",
        "  query = np.dot(input_embeddings, w_q)\n",
        "  key = np.dot(input_embeddings, w_k)\n",
        "  value = np.dot(input_embeddings, w_v)\n",
        "\n",
        "  '''Calculate the Dot Product of the Query & Key Matrices'''\n",
        "  dot_product = np.dot(query, key.T)\n",
        "\n",
        "  '''scale the dot product'''\n",
        "  scaling_factor = np.sqrt(embedding_dim)\n",
        "  scaled_dot_product = dot_product / scaling_factor\n",
        "\n",
        "  '''Apply the Softmax function'''\n",
        "  attention_scores = np.exp(scaled_dot_product) / np.sum(np.exp(scaled_dot_product),\n",
        "                                                         axis=1, keepdims=True)\n",
        "\n",
        "  '''Multiply the attention weights with value matrix\n",
        "  to get the context aware embeddings'''\n",
        "  context_aware_embeddings = np.dot(attention_scores, value)\n",
        "\n",
        "  return context_aware_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input_embedding = np.array([[1.0, 0.5, 0.1, 0.9],\n",
        "                                 [0.2, 0.8,0.3, 0.7],\n",
        "                                 [0.6, 0.4, 0.9, 0.2]])"
      ],
      "metadata": {
        "id": "5NJDzBv0NfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T5cmfsNNw2Q",
        "outputId": "cccc46d1-b17b-47bd-c12d-e4f0b4096b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 0.5, 0.1, 0.9],\n",
              "       [0.2, 0.8, 0.3, 0.7],\n",
              "       [0.6, 0.4, 0.9, 0.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_output = self_attention(dummy_input_embedding)\n",
        "print(\"Input Embedding Shape: \", dummy_input_embedding.shape)\n",
        "print(\"Self Attention Output Shape: \", attention_output.shape)\n",
        "print(\"\\nSelf Attention Output: \")\n",
        "display(attention_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "LadewFsXN0a9",
        "outputId": "49ba7f67-22f5-4b45-eeda-18ac38a4744d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Embedding Shape:  (3, 4)\n",
            "Self Attention Output Shape:  (3, 4)\n",
            "\n",
            "Self Attention Output: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-0.57503119, -2.1879209 , -0.81559203,  0.13203132],\n",
              "       [-0.52521002, -2.15388727, -0.66038186, -0.027201  ],\n",
              "       [-0.50599814, -2.13978587, -0.63096139, -0.0603008 ]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55-yF2GZN7T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e43a2b6"
      },
      "source": [
        "# Task\n",
        "Implement a Multi-Head Attention function in Python, provide an example demonstrating its usage and calculation, and summarize the entire code for a beginner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d264dbbb"
      },
      "source": [
        "## Implement multi-head attention\n",
        "\n",
        "### Subtask:\n",
        "Write Python code for a Multi-Head Attention function, utilizing the Self-Attention function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49efc541"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the multi-head attention function as per the instructions, ensuring the embedding dimension is divisible by the number of heads and calculating the output by combining the results from multiple self-attention heads.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d762077"
      },
      "source": [
        "def multi_head_attention(input_embeddings, num_heads, embedding_dim):\n",
        "    \"\"\"Applies Multi-Head Attention to input embeddings.\"\"\"\n",
        "\n",
        "    if embedding_dim % num_heads != 0:\n",
        "        raise ValueError(\"embedding_dim must be divisible by num_heads\")\n",
        "\n",
        "    sentence_length, _ = input_embeddings.shape\n",
        "    head_dim = embedding_dim // num_heads\n",
        "    attention_outputs = []\n",
        "\n",
        "    np.random.seed(42) # Use the same seed for reproducibility\n",
        "\n",
        "    for _ in range(num_heads):\n",
        "        # Define the Learnable Weight Matrices for Query, Key and Value for each head\n",
        "        w_q = np.random.randn(embedding_dim, head_dim)\n",
        "        w_k = np.random.randn(embedding_dim, head_dim)\n",
        "        w_v = np.random.randn(embedding_dim, head_dim)\n",
        "\n",
        "        # Calculate the dot product of Query, Key and Value Matrices for each head\n",
        "        query = np.dot(input_embeddings, w_q)\n",
        "        key = np.dot(input_embeddings, w_k)\n",
        "        value = np.dot(input_embeddings, w_v)\n",
        "\n",
        "        # Calculate the Dot Product of the Query & Key Matrices for each head\n",
        "        dot_product = np.dot(query, key.T)\n",
        "\n",
        "        # Scale the dot product\n",
        "        scaling_factor = np.sqrt(head_dim)\n",
        "        scaled_dot_product = dot_product / scaling_factor\n",
        "\n",
        "        # Apply the Softmax function\n",
        "        attention_scores = np.exp(scaled_dot_product) / np.sum(np.exp(scaled_dot_product),\n",
        "                                                         axis=1, keepdims=True)\n",
        "\n",
        "        # Multiply the attention weights with value matrix to get the context aware embeddings for each head\n",
        "        context_aware_embeddings = np.dot(attention_scores, value)\n",
        "        attention_outputs.append(context_aware_embeddings)\n",
        "\n",
        "    # Concatenate the context-aware embeddings from all heads\n",
        "    concatenated_output = np.concatenate(attention_outputs, axis=-1)\n",
        "\n",
        "    # Define and initialize the final weight matrix which is nothing but the Linear Transformation...\n",
        "    w_o = np.random.randn(embedding_dim, embedding_dim)\n",
        "\n",
        "    # Multiply the concatenated output with w_o\n",
        "    final_output = np.dot(concatenated_output, w_o)\n",
        "\n",
        "    return final_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7d6e2e"
      },
      "source": [
        "## Provide an example\n",
        "\n",
        "### Subtask:\n",
        "Generate code to demonstrate the Multi-Head Attention function with example input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72b3a5da"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate code to demonstrate the Multi-Head Attention function with example input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "17fd4cd0",
        "outputId": "f372f55f-c142-4c87-f4f0-edf2a0d916ee"
      },
      "source": [
        "# 1. Define example input embeddings\n",
        "example_input_embeddings = np.array([[1.0, 0.5, 0.1, 0.9, 0.7, 0.3],\n",
        "                                     [0.2, 0.8, 0.3, 0.7, 0.1, 0.6],\n",
        "                                     [0.6, 0.4, 0.9, 0.2, 0.8, 0.5],\n",
        "                                     [0.3, 0.7, 0.5, 0.8, 0.2, 0.9]])\n",
        "\n",
        "# 2. Choose a number of heads and determine embedding dimension\n",
        "num_heads = 2\n",
        "embedding_dim = example_input_embeddings.shape[1]\n",
        "\n",
        "# 3. Call the multi_head_attention function\n",
        "multi_head_output = multi_head_attention(example_input_embeddings, num_heads, embedding_dim)\n",
        "\n",
        "# 4. Print the shape of input and output\n",
        "print(\"Example Input Embedding Shape: \", example_input_embeddings.shape)\n",
        "print(\"Multi-Head Attention Output Shape: \", multi_head_output.shape)\n",
        "\n",
        "# 5. Display the output\n",
        "print(\"\\nMulti-Head Attention Output: \")\n",
        "display(multi_head_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Input Embedding Shape:  (4, 6)\n",
            "Multi-Head Attention Output Shape:  (4, 6)\n",
            "\n",
            "Multi-Head Attention Output: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[-0.40806063,  1.43719391,  1.42597716, -1.41306515,  2.0036171 ,\n",
              "        -1.78655919],\n",
              "       [-0.83102709,  1.26734153,  0.94260042, -0.23859147,  0.7989667 ,\n",
              "        -2.10523193],\n",
              "       [-0.42020797,  1.4546778 ,  1.52831819, -1.66362185,  2.21923997,\n",
              "        -1.63638085],\n",
              "       [-0.75761174,  1.28216562,  1.05766187, -0.48588246,  1.02977724,\n",
              "        -1.99849954]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49378d5"
      },
      "source": [
        "## Summarize the code\n",
        "\n",
        "### Subtask:\n",
        "Create a markdown cell summarizing all the code cells for a beginner.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06705548"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to create a markdown cell to summarize the code cells for a beginner, as requested in the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Summary for Beginners\n",
        "\n",
        "Let's break down the code in this notebook step by step so you can understand what's happening, even if you're new to this!\n",
        "\n",
        "*   **Code Cell 1: The `self_attention` Function**\n",
        "    This is like the basic building block of our attention mechanism. Think of it as a way for the computer to figure out which parts of an input (like words in a sentence) are most important and how they relate to each other. The function takes in some \"embeddings\" (numerical representations of our input) and calculates \"attention scores.\" These scores essentially tell us how much focus to put on each part of the input when processing it. The output is \"context-aware embeddings,\" which are updated representations that now understand the relationships between the different parts of the input.\n",
        "\n",
        "*   **Code Cell 2 & 3: Example Input Data**\n",
        "    These cells just create some simple, fake data to test our functions. `dummy_input_embedding` is a small set of numbers that act as our example \"input embeddings.\" We use this so we can see how our attention functions work with a concrete example.\n",
        "\n",
        "*   **Code Cell 4: Testing `self_attention`**\n",
        "    Here, we use our `dummy_input_embedding` and run it through the `self_attention` function we defined earlier. The output, `attention_output`, is the result of the basic attention calculation on our example data. We print the shapes to see that the output has the same structure as the input, and then display the actual numbers that represent the context-aware embeddings.\n",
        "\n",
        "*   **Code Cell 5: The `multi_head_attention` Function**\n",
        "    This is an advanced version of the basic `self_attention`. Instead of just one \"head\" (like in `self_attention`), `multi_head_attention` uses multiple \"heads\" working in parallel. Each head can focus on different aspects of the input relationships. Imagine looking at something from different angles – multi-head attention does something similar for the data. It runs the attention process several times with different perspectives and then combines the results to get a richer understanding of the input. This usually leads to better performance in models.\n",
        "\n",
        "*   **Code Cell 6: Testing `multi_head_attention`**\n",
        "    Similar to testing `self_attention`, this cell uses an example input (`example_input_embeddings`) to show how the `multi_head_attention` function works. We specify how many \"heads\" we want to use (`num_heads`) and then call the function. The output (`multi_head_output`) is the result of applying multi-head attention to our example data. We print the shapes to confirm the input and output dimensions and then display the resulting context-aware embeddings from the multi-head process.\n"
      ],
      "metadata": {
        "id": "ZgfP5bovP6bc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fc5e9a"
      },
      "source": [
        "## Summarize the code\n",
        "\n",
        "### Subtask:\n",
        "Create a markdown cell summarizing all the code cells for a beginner.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "154bdcb3"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to create a markdown cell summarizing the code cells. Since I cannot directly create a markdown cell with content, I will create a code cell with the markdown content as a string within a print statement. This will effectively display the summary in the output of the cell, which is the closest I can get to fulfilling the request given the environment's limitations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0882fa16",
        "outputId": "56e2cd3a-5213-4265-c6e2-ac3096bdc6f0"
      },
      "source": [
        "print(\"\"\"### Code Summary for Beginners\n",
        "\n",
        "Let's break down the code in this notebook step by step so you can understand what's happening, even if you're new to this!\n",
        "\n",
        "*   **Code Cell 1: The `self_attention` Function**\n",
        "    This is like the basic building block of our attention mechanism. Think of it as a way for the computer to figure out which parts of an input (like words in a sentence) are most important and how they relate to each other. The function takes in some \"embeddings\" (numerical representations of our input) and calculates \"attention scores.\" These scores essentially tell us how much focus to put on each part of the input when processing it. The output is \"context-aware embeddings,\" which are updated representations that now understand the relationships between the different parts of the input.\n",
        "\n",
        "*   **Code Cell 2 & 3: Example Input Data**\n",
        "    These cells just create some simple, fake data to test our functions. `dummy_input_embedding` is a small set of numbers that act as our example \"input embeddings.\" We use this so we can see how our attention functions work with a concrete example.\n",
        "\n",
        "*   **Code Cell 4: Testing `self_attention`**\n",
        "    Here, we use our `dummy_input_embedding` and run it through the `self_attention` function we defined earlier. The output, `attention_output`, is the result of the basic attention calculation on our example data. We print the shapes to see that the output has the same structure as the input, and then display the actual numbers that represent the context-aware embeddings.\n",
        "\n",
        "*   **Code Cell 5: The `multi_head_attention` Function**\n",
        "    This is an advanced version of the basic `self_attention`. Instead of just one \"head\" (like in `self_attention`), `multi_head_attention` uses multiple \"heads\" working in parallel. Each head can focus on different aspects of the input relationships. Imagine looking at something from different angles – multi-head attention does something similar for the data. It runs the attention process several times with different perspectives and then combines the results to get a richer understanding of the input. This usually leads to better performance in models.\n",
        "\n",
        "*   **Code Cell 6: Testing `multi_head_attention`**\n",
        "    Similar to testing `self_attention`, this cell uses an example input (`example_input_embeddings`) to show how the `multi_head_attention` function works. We specify how many \"heads\" we want to use (`num_heads`) and then call the function. The output (`multi_head_output`) is the result of applying multi-head attention to our example data. We print the shapes to confirm the input and output dimensions and then display the resulting context-aware embeddings from the multi-head process.\n",
        "\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Code Summary for Beginners\n",
            "\n",
            "Let's break down the code in this notebook step by step so you can understand what's happening, even if you're new to this!\n",
            "\n",
            "*   **Code Cell 1: The `self_attention` Function**\n",
            "    This is like the basic building block of our attention mechanism. Think of it as a way for the computer to figure out which parts of an input (like words in a sentence) are most important and how they relate to each other. The function takes in some \"embeddings\" (numerical representations of our input) and calculates \"attention scores.\" These scores essentially tell us how much focus to put on each part of the input when processing it. The output is \"context-aware embeddings,\" which are updated representations that now understand the relationships between the different parts of the input.\n",
            "\n",
            "*   **Code Cell 2 & 3: Example Input Data**\n",
            "    These cells just create some simple, fake data to test our functions. `dummy_input_embedding` is a small set of numbers that act as our example \"input embeddings.\" We use this so we can see how our attention functions work with a concrete example.\n",
            "\n",
            "*   **Code Cell 4: Testing `self_attention`**\n",
            "    Here, we use our `dummy_input_embedding` and run it through the `self_attention` function we defined earlier. The output, `attention_output`, is the result of the basic attention calculation on our example data. We print the shapes to see that the output has the same structure as the input, and then display the actual numbers that represent the context-aware embeddings.\n",
            "\n",
            "*   **Code Cell 5: The `multi_head_attention` Function**\n",
            "    This is an advanced version of the basic `self_attention`. Instead of just one \"head\" (like in `self_attention`), `multi_head_attention` uses multiple \"heads\" working in parallel. Each head can focus on different aspects of the input relationships. Imagine looking at something from different angles – multi-head attention does something similar for the data. It runs the attention process several times with different perspectives and then combines the results to get a richer understanding of the input. This usually leads to better performance in models.\n",
            "\n",
            "*   **Code Cell 6: Testing `multi_head_attention`**\n",
            "    Similar to testing `self_attention`, this cell uses an example input (`example_input_embeddings`) to show how the `multi_head_attention` function works. We specify how many \"heads\" we want to use (`num_heads`) and then call the function. The output (`multi_head_output`) is the result of applying multi-head attention to our example data. We print the shapes to confirm the input and output dimensions and then display the resulting context-aware embeddings from the multi-head process.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1928f559"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `multi_head_attention` function was successfully implemented, handling the division of `embedding_dim` by `num_heads` and applying scaled dot-product attention across multiple heads.\n",
        "*   An example demonstration of the `multi_head_attention` function confirmed that the output shape is the same as the input shape, preserving the sequence length and embedding dimension.\n",
        "*   A summary of the code for beginners was generated as markdown content within a code cell's output, explaining the purpose of each code block and the core concepts of self-attention and multi-head attention.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current implementation uses randomly initialized weight matrices. For a practical deep learning model, these weights would be learnable parameters updated during training.\n",
        "*   Future steps could involve integrating this multi-head attention function into a larger neural network architecture, such as a Transformer model, and training it on a specific task like machine translation or text classification.\n"
      ]
    }
  ]
}