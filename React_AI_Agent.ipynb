{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpji1Lc1bLnG0FMTe+plrw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukul-mschauhan/GenerativeAI/blob/main/React_AI_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "148e1961"
      },
      "source": [
        "# AI Agents\n",
        "Create a Google Colab notebook that implements an AI agent using the ReACT (Reason+Act) paradigm. This notebook should include:\n",
        "1.  **Introduction**: Markdown cells explaining AI agents, ReACT, the role of tools (specifically Tavily for web search), and the concept of a 'Decision Trace'.\n",
        "2.  **Setup**: Code cells for installing necessary Python packages (`openai`, `tavily-python`, `gradio`) and securely setting `OPENAI_API_KEY` and `TAVILY_API_KEY` environment variables with robust error handling.\n",
        "3.  **Tavily Search Tool**: A Python function `tavily_search` to interact with the Tavily API, returning structured search results (title, URL, content/snippet) with error handling.\n",
        "4.  **Search Gating Logic**: A Python function `should_use_tavily` that determines whether to use web search based on the user's query (e.g., for recency, factual lookups, keywords like 'latest', 'verify'), providing a boolean decision and a reason.\n",
        "5.  **ReACT Agent Core**: A Python function (e.g., `run_agent`) that serves as the core agent logic. It should take a user query, use `should_use_tavily` to decide on web search, execute `tavily_search` if needed, and then use the OpenAI API to synthesize a final answer. This function must construct a 'Decision Trace' and a 'Tool Trace'.\n",
        "6.  **Gradio Interactive Frontend**: A Gradio interface with a textbox for user input, a 'Mode' dropdown ('Teach Mode' to show all traces, 'Normal Mode' to show only the final answer), and a 'Clear' button. The UI should display 'User question', 'Decision Trace', 'Tool Trace', and 'Final Answer'. Preload example questions like 'What is a ReACT agent? Explain with audit analogy.', 'What are the latest UAE VAT updates?', and 'Create an audit evidence request list for revenue testing.'. The app should run in Colab with `share=False`.\n",
        "7.  **Output Formatting**: Ensure the agent's output is consistently formatted into distinct sections: 'Decision Trace' (Search needed? Yes/No, Why?), 'Tool Trace' (search query + results if searched, otherwise 'No external tools used'), and 'Final Answer' (helpful, adopt a UAE audit/accounting tone, with citations if web search was used).\n",
        "8.  **Educational Lab Exercise**: A markdown cell detailing a mini-lab exercise that prompts users to modify the `should_use_tavily` gating rules and observe the agent's behavior.\n",
        "The notebook should be self-contained and ready for execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ec6aa17"
      },
      "source": [
        "## Notebook Introduction and Setup\n",
        "\n",
        "### Subtask:\n",
        "Create a markdown cell explaining AI agents, ReACT, the role of tools (Tavily), and Decision Trace. Then, add code cells to install necessary Python packages and securely set API keys.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d648582c"
      },
      "source": [
        "## Notebook Introduction and Setup\n",
        "\n",
        "### Subtask:\n",
        "Create a markdown cell explaining AI agents, ReACT, the role of tools (Tavily), and Decision Trace. Then, add code cells to install necessary Python packages and securely set API keys.\n",
        "\n",
        "# AI Agent with ReACT Paradigm\n",
        "\n",
        "### What is an AI agent?\n",
        "An AI agent is a program designed to perceive its environment through sensors, process that information, and then act upon that environment through effectors to achieve specific goals. Unlike simple scripts, agents can make decisions, learn, and adapt to changing conditions. They often employ sophisticated reasoning mechanisms and can utilize various tools to extend their capabilities.\n",
        "\n",
        "### What is ReACT (Reason+Act)?\n",
        "ReACT stands for \"Reason + Act\". It's a paradigm for designing AI agents where the agent explicitly *reasons* about a problem, *plans* its next steps, and then *acts* based on that plan. This iterative process allows the agent to break down complex tasks into smaller, manageable subtasks, use tools effectively, and self-correct when faced with unexpected outcomes. It improves the agent's transparency, reliability, and capability to handle more intricate challenges.\n",
        "\n",
        "### What is the role of tools (specifically Tavily for web search)?\n",
        "Tools empower AI agents by extending their capabilities beyond their inherent knowledge. They allow agents to interact with the external world, retrieve up-to-date information, perform computations, or even control other software. Tavily, for instance, serves as a powerful web search tool. When an agent needs information not contained within its training data or requires real-time data, it can use Tavily to perform a web search, analyze the results, and incorporate that fresh information into its reasoning process, thus making more informed decisions.\n",
        "\n",
        "### Why we show Decision Trace instead of private reasoning\n",
        "In AI agent development, especially with complex models, the internal \"thought process\" or \"private reasoning\" can be very intricate and often difficult to interpret directly. A \"Decision Trace\" is a structured log of the agent's thought process, showcasing the key steps it takes: what it observes, what it reasons, what tool it decides to use, the input to that tool, and the tool's output, leading to its final action. Showing the decision trace helps in:\n",
        "1.  **Transparency:** Understanding *how* the agent arrived at a particular conclusion or action.\n",
        "2.  **Debugging:** Identifying where the agent's reasoning might have gone astray.\n",
        "3.  **Trust:** Building user confidence by demonstrating a logical flow of operations.\n",
        "4.  **Learning:** Providing insights into agent behavior for further refinement and improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8cfc517"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to install the necessary Python packages as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e65e63e6",
        "outputId": "51d1c908-4f71-4934-8f3e-e84d5fa514d2"
      },
      "source": [
        "pip install openai tavily-python gradio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.17-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.12.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2025.11.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading tavily_python-0.7.17-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.7.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b520d97"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to securely set the API keys for OpenAI and Tavily, including robust error handling, as specified in the instructions. This ensures the agent can interact with these services.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35573474",
        "outputId": "bbedac52-7e52-4000-815e-92ddfde312c2"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "def set_api_key(api_key_name):\n",
        "    \"\"\"Sets an API key from environment variable or user input.\"\"\"\n",
        "    if api_key_name not in os.environ:\n",
        "        os.environ[api_key_name] = getpass(f\"Enter your {api_key_name}:\")\n",
        "\n",
        "    if not os.environ.get(api_key_name):\n",
        "        raise ValueError(f\"{api_key_name} is not set. Please set the API key to proceed.\")\n",
        "    print(f\"{api_key_name} is set.\")\n",
        "\n",
        "try:\n",
        "    set_api_key(\"OPENAI_API_KEY\")\n",
        "    set_api_key(\"TAVILY_API_KEY\")\n",
        "    print(\"All necessary API keys are securely set.\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Please ensure you enter valid API keys when prompted or set them as environment variables.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OPENAI_API_KEY:··········\n",
            "OPENAI_API_KEY is set.\n",
            "Enter your TAVILY_API_KEY:··········\n",
            "TAVILY_API_KEY is set.\n",
            "All necessary API keys are securely set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0896caea"
      },
      "source": [
        "## Implement Tavily Search Tool\n",
        "\n",
        "### Subtask:\n",
        "Define the `tavily_search` function to interact with the Tavily API, returning structured search results with error handling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fefe5aff"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `tavily_search` function as specified, which includes importing `TavilyClient`, instantiating it, handling potential errors, and structuring the search results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c583e2c5",
        "outputId": "a646c5b7-a188-4424-ffa1-e4f06c508c32"
      },
      "source": [
        "import os\n",
        "from tavily import TavilyClient\n",
        "\n",
        "def tavily_search(query: str, max_results: int = 5) -> list:\n",
        "    \"\"\"\n",
        "    Performs a web search using the Tavily API and returns structured results.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query.\n",
        "        max_results (int): The maximum number of search results to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing 'title', 'url', and 'content' of a search result.\n",
        "              Returns an empty list if an error occurs or no results are found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tavily_client = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))\n",
        "        response = tavily_client.search(\n",
        "            query=query,\n",
        "            search_depth='advanced',\n",
        "            max_results=max_results\n",
        "        )\n",
        "\n",
        "        structured_results = []\n",
        "        for result in response.get('results', []):\n",
        "            structured_results.append({\n",
        "                'title': result.get('title'),\n",
        "                'url': result.get('url'),\n",
        "                'content': result.get('content')\n",
        "            })\n",
        "        return structured_results\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Tavily search: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"The `tavily_search` function is defined and ready for use.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The `tavily_search` function is defined and ready for use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38a363cc"
      },
      "source": [
        "## Implement Search Gating Logic\n",
        "\n",
        "### Subtask:\n",
        "Create the `should_use_tavily` function that determines whether to use web search based on the user's query, providing a boolean decision and a reason.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ba4268"
      },
      "source": [
        "**Reasoning**:\n",
        "I will now define the `should_use_tavily` function. This function is crucial for the agent's efficiency, as it prevents unnecessary API calls to Tavily for queries that can be answered from the agent's internal knowledge or are purely conceptual. The logic will involve checking for specific keywords or phrases that indicate a need for up-to-date information, factual verification, or external data, while also identifying queries that are generic or conceptual and do not require a web search. This function will return a boolean indicating whether to use Tavily and a string explaining the decision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "184ec98f"
      },
      "source": [
        "**Reasoning**:\n",
        "Now I will implement the `should_use_tavily` function based on the detailed instructions provided, including keyword detection for web search necessity and identification of conceptual queries, ensuring case-insensitivity and returning a boolean and a reason.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f93ea84",
        "outputId": "a051ff94-a315-458f-b576-a36ca6ba85a0"
      },
      "source": [
        "def should_use_tavily(user_query: str) -> tuple[bool, str]:\n",
        "    \"\"\"\n",
        "    Determines whether a web search using Tavily is necessary based on the user's query.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's input query.\n",
        "\n",
        "    Returns:\n",
        "        tuple[bool, str]: A tuple containing a boolean (True if Tavily should be used, False otherwise)\n",
        "                         and a string explaining the decision.\n",
        "    \"\"\"\n",
        "    use_tavily = False\n",
        "    reason = \"Query appears conceptual or does not contain keywords suggesting a need for web search.\"\n",
        "\n",
        "    # Convert query to lowercase for case-insensitive checking\n",
        "    query_lower = user_query.lower()\n",
        "\n",
        "    # Keywords indicating a need for web search (recency, factual lookup)\n",
        "    search_keywords = [\n",
        "        'latest', 'today', 'news', 'current', 'recent', 'updates',\n",
        "        'verify', 'what are the', 'who is the', 'when was', 'how many',\n",
        "        'statistics', 'report', 'data', 'facts', 'figures', 'policy', 'regulation'\n",
        "    ]\n",
        "\n",
        "    # Phrases/patterns indicating conceptual or evergreen queries (less likely to need search)\n",
        "    conceptual_phrases = [\n",
        "        'what is a', 'explain', 'define', 'how does', 'what are the principles',\n",
        "        'describe', 'tell me about', 'analogy'\n",
        "    ]\n",
        "\n",
        "    # Check for keywords suggesting a need for web search\n",
        "    if any(keyword in query_lower for keyword in search_keywords):\n",
        "        use_tavily = True\n",
        "        reason = \"Query contains keywords (e.g., 'latest', 'verify', 'current') indicating a need for recent information or factual lookup.\"\n",
        "\n",
        "    # Refine decision for conceptual queries if a search keyword was NOT found\n",
        "    elif any(phrase in query_lower for phrase in conceptual_phrases):\n",
        "        use_tavily = False\n",
        "        reason = \"Query appears conceptual and does not require external search. Internal knowledge is likely sufficient.\"\n",
        "\n",
        "    # If still False, but query asks for specific entity that might need external context (e.g., specific company name)\n",
        "    # This is a basic example and could be enhanced with named entity recognition.\n",
        "    elif len(query_lower.split()) > 4 and not use_tavily: # Heuristic for more specific queries\n",
        "        use_tavily = False # Default to false for general longer queries unless a specific keyword is hit\n",
        "        reason = \"Query is general and likely answerable from internal knowledge base.\"\n",
        "\n",
        "    # If after all checks, it's still not decided, and it's a moderately complex query, default to search\n",
        "    if not use_tavily and len(query_lower.split()) > 6 and '?' in query_lower:\n",
        "        use_tavily = True\n",
        "        reason = \"Query is ambiguous or complex; defaulting to web search to ensure comprehensive and up-to-date information.\"\n",
        "\n",
        "    # Override if specific 'latest' or 'verify' type words are present, ensuring search\n",
        "    if 'latest' in query_lower or 'verify' in query_lower or 'current' in query_lower:\n",
        "        use_tavily = True\n",
        "        reason = \"Query explicitly requests latest/current information or verification, requiring a web search.\"\n",
        "\n",
        "    return use_tavily, reason\n",
        "\n",
        "print(\"The `should_use_tavily` function is defined and ready for use.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The `should_use_tavily` function is defined and ready for use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66f7bba0"
      },
      "source": [
        "## Implement ReACT Agent Core\n",
        "\n",
        "### Subtask:\n",
        "Create a Python function (e.g., `run_agent`) that serves as the core agent logic. It should take a user query, use `should_use_tavily` to decide on web search, execute `tavily_search` if needed, and then use the OpenAI API to synthesize a final answer. This function must construct a 'Decision Trace' and a 'Tool Trace'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "755870a9"
      },
      "source": [
        "## Develop ReACT Agent Core\n",
        "\n",
        "### Subtask:\n",
        "Build the core ReACT-style agent logic within a function (e.g., `run_agent`). This function will take a user query, interpret intent, call `should_use_tavily` to decide on web search, execute `tavily_search` if needed, and then use the OpenAI API (Responses or Chat Completions) to synthesize a final answer. The agent will construct the 'Decision Trace' (high-level, non-sensitive reasons for search decision) and 'Tool Trace' (search query, top results with title/URL if search was performed).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e18aa57"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to implement the `run_agent` function as specified in the instructions, which will orchestrate the entire ReACT agent logic, including calling `should_use_tavily`, `tavily_search`, and the OpenAI API, while constructing the 'Decision Trace' and 'Tool Trace'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f520a729",
        "outputId": "2757b426-3dc9-41d3-98ca-8249ed86054c"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Ensure should_use_tavily and tavily_search functions are defined or imported here if they were in a separate cell\n",
        "# For simplicity, assuming they are accessible in the current scope from previous steps.\n",
        "\n",
        "def run_agent(user_query: str, mode: str = 'Normal Mode') -> tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    Core ReACT-style agent logic to process a user query, decide on web search, execute it if needed,\n",
        "    and synthesize a final answer using the OpenAI API.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's input query.\n",
        "        mode (str): The operational mode, either 'Normal Mode' or 'Teach Mode'.\n",
        "\n",
        "    Returns:\n",
        "        tuple[str, str, str]: decision_trace, tool_trace, final_answer.\n",
        "    \"\"\"\n",
        "    decision_trace = \"\"\n",
        "    tool_trace = \"\"\n",
        "    final_answer = \"\"\n",
        "\n",
        "    # 1. Decide if web search is needed\n",
        "    use_tavily, reason = should_use_tavily(user_query)\n",
        "\n",
        "    # 2. Construct Decision Trace\n",
        "    decision_trace = f\"Search needed: {'Yes' if use_tavily else 'No'}. Reason: {reason}\"\n",
        "\n",
        "    search_results = []\n",
        "    openai_context = \"\"\n",
        "\n",
        "    # 3. Execute web search if needed\n",
        "    if use_tavily:\n",
        "        try:\n",
        "            search_results = tavily_search(user_query)\n",
        "            if search_results:\n",
        "                # Format search results for OpenAI context\n",
        "                formatted_results = []\n",
        "                for i, result in enumerate(search_results):\n",
        "                    formatted_results.append(f\"Source {i+1}:\\nTitle: {result.get('title', 'N/A')}\\nURL: {result.get('url', 'N/A')}\\nContent: {result.get('content', 'N/A')}\")\n",
        "                openai_context = \"\\n\\n\" + \"\\n\\n\".join(formatted_results)\n",
        "\n",
        "                # Construct Tool Trace with top results\n",
        "                tool_trace_content = []\n",
        "                for i, result in enumerate(search_results):\n",
        "                    tool_trace_content.append(f\"Title: {result.get('title')}, URL: {result.get('url')}\")\n",
        "                tool_trace = f\"Search Query: {user_query}\\n\\nResults (Top {len(tool_trace_content)}):\\n\" + \"\\n\".join(tool_trace_content)\n",
        "            else:\n",
        "                tool_trace = f\"Search Query: {user_query}\\n\\nNo relevant results found.\"\n",
        "        except Exception as e:\n",
        "            tool_trace = f\"Search Query: {user_query}\\n\\nError during search: {e}\"\n",
        "            openai_context = \"\"\n",
        "    else:\n",
        "        tool_trace = \"No external tools used.\"\n",
        "\n",
        "    # 4. Define system prompt\n",
        "    system_prompt = (\n",
        "        \"You are an expert auditor and accountant in the UAE. Your role is to provide helpful, accurate, and clear answers to financial and audit-related questions, adopting a professional tone. \"\n",
        "        \"If you use information from web search results, you MUST cite the source (e.g., [1] Title - URL). \"\n",
        "        \"Explain complex concepts clearly, using relevant audit or accounting analogies where appropriate to enhance understanding. \"\n",
        "        \"Ensure your answers are concise yet comprehensive, addressing all aspects of the user's query. \"\n",
        "        \"Always adhere to UAE-specific regulations and practices when applicable.\"\n",
        "    )\n",
        "\n",
        "    # 5. Create messages for OpenAI API\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt}\n",
        "    ]\n",
        "\n",
        "    user_message_content = f\"User Query: {user_query}\"\n",
        "    if openai_context:\n",
        "        user_message_content += f\"\\n\\nHere are some relevant web search results for context:\\n{openai_context}\"\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_message_content})\n",
        "\n",
        "    # 6. Initialize OpenAI client and make API call\n",
        "    try:\n",
        "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\", # Using gpt-4o as specified\n",
        "            messages=messages,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        final_answer = response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        final_answer = f\"An error occurred while generating the response: {e}\"\n",
        "        if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "            final_answer += \"\\nPlease ensure OPENAI_API_KEY is correctly set.\"\n",
        "\n",
        "    return decision_trace, tool_trace, final_answer\n",
        "\n",
        "print(\"The `run_agent` function is defined and ready.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The `run_agent` function is defined and ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff618851"
      },
      "source": [
        "## Build Gradio Interactive Frontend\n",
        "\n",
        "### Subtask:\n",
        "Construct the Gradio interface for the agent, including user input, mode selection, clear button, and displaying traces and final answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "346c6174"
      },
      "source": [
        "**Reasoning**:\n",
        "I will implement the Gradio interface as per the instructions, which involves importing the Gradio library, defining a wrapper function to handle mode-based output formatting, creating the Gradio interface with appropriate input/output components, setting up example questions, and launching the application.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "17c29f40",
        "outputId": "d33ca467-b422-4e9e-8d9f-f504e96615b6"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "def run_agent_gradio(user_query: str, mode: str) -> tuple[str, str, str, str, str]:\n",
        "    \"\"\"\n",
        "    Wrapper function to call the core agent logic and format output for Gradio.\n",
        "    It also handles conditional display of traces based on the selected mode.\n",
        "    \"\"\"\n",
        "    # Call the core agent logic\n",
        "    decision_trace, tool_trace, final_answer = run_agent(user_query, mode)\n",
        "\n",
        "    # Prepare outputs for Gradio\n",
        "    output_decision_trace = decision_trace\n",
        "    output_tool_trace = tool_trace\n",
        "    output_final_answer = final_answer\n",
        "    output_user_question = f\"User question: {user_query}\"\n",
        "\n",
        "    # Conditional visibility based on mode\n",
        "    if mode == 'Normal Mode':\n",
        "        return output_user_question, output_final_answer, gr.update(value=None, visible=False), gr.update(value=None, visible=False), gr.update(value=output_final_answer, visible=True)\n",
        "    else: # Teach Mode\n",
        "        return output_user_question, output_final_answer, gr.update(value=output_decision_trace, visible=True), gr.update(value=output_tool_trace, visible=True), gr.update(value=output_final_answer, visible=True)\n",
        "\n",
        "# Create Gradio Interface\n",
        "with gr.Blocks(title=\"AI Agent with ReACT Paradigm\") as demo:\n",
        "    gr.Markdown(\"# AI Agent with ReACT Paradigm\")\n",
        "    gr.Markdown(\"Explore the capabilities of an AI Agent using the ReACT paradigm. Select 'Teach Mode' to see the agent's decision-making process (Decision Trace, Tool Trace) or 'Normal Mode' for just the final answer.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        query_input = gr.Textbox(label='Enter your question:', placeholder='e.g., What is an AI Agent?', lines=2)\n",
        "        mode_dropdown = gr.Dropdown(choices=['Normal Mode', 'Teach Mode'], label='Mode', value='Normal Mode')\n",
        "\n",
        "    run_button = gr.Button('Run Agent')\n",
        "\n",
        "    user_question_output = gr.Textbox(label='User Question', interactive=False, visible=True)\n",
        "    decision_trace_output = gr.Textbox(label='Decision Trace', interactive=False, visible=False, lines=3)\n",
        "    tool_trace_output = gr.Textbox(label='Tool Trace', interactive=False, visible=False, lines=5)\n",
        "    final_answer_output = gr.Textbox(label='Final Answer', interactive=False, visible=True, lines=10)\n",
        "\n",
        "    # Initialize ClearButton with components to clear\n",
        "    clear_button = gr.ClearButton(components=[query_input, user_question_output, decision_trace_output, tool_trace_output, final_answer_output])\n",
        "\n",
        "    # Define the outputs based on mode\n",
        "    outputs = [\n",
        "        user_question_output,\n",
        "        final_answer_output,\n",
        "        decision_trace_output,\n",
        "        tool_trace_output,\n",
        "        final_answer_output # This is intentionally duplicated to handle the case where only final_answer needs to be updated for visibility\n",
        "    ]\n",
        "\n",
        "    # Event handler for the Run button\n",
        "    run_button.click(\n",
        "        fn=run_agent_gradio,\n",
        "        inputs=[query_input, mode_dropdown],\n",
        "        outputs=outputs\n",
        "    )\n",
        "\n",
        "    # Define examples\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            ['What is a ReACT agent? Explain with audit analogy.', 'Teach Mode'],\n",
        "            ['What are the latest UAE VAT updates?', 'Normal Mode'],\n",
        "            ['Create an audit evidence request list for revenue testing.', 'Normal Mode']\n",
        "        ],\n",
        "        inputs=[query_input, mode_dropdown],\n",
        "        fn=run_agent_gradio,\n",
        "        outputs=outputs,\n",
        "        cache_examples=False\n",
        "    )\n",
        "\n",
        "# Launch the Gradio app\n",
        "print(\"Launching Gradio app...\")\n",
        "demo.launch(share=False)\n",
        "print(\"Gradio app launched.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Gradio app...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradio app launched.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e21e878"
      },
      "source": [
        "## Integrate Agent Output Formatting\n",
        "\n",
        "### Subtask:\n",
        "Review and confirm that the agent's output is consistently formatted into distinct sections ('Decision Trace', 'Tool Trace', 'Final Answer') as specified, including the UAE audit/accounting tone and citations for the final answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eec521e"
      },
      "source": [
        "### Review of `run_agent` function - Trace Construction\n",
        "\n",
        "#### Decision Trace:\n",
        "\n",
        "The `run_agent` function constructs the `decision_trace` as follows:\n",
        "\n",
        "```python\n",
        "decision_trace = f\"Search needed: {'Yes' if use_tavily else 'No'}. Reason: {reason}\"\n",
        "```\n",
        "\n",
        "This format directly matches the requirement: \"'Search needed? Yes/No, Why?'\".\n",
        "\n",
        "#### Tool Trace:\n",
        "\n",
        "If `use_tavily` is `True` and `search_results` are found, the `tool_trace` is constructed as:\n",
        "\n",
        "```python\n",
        "tool_trace_content = []\n",
        "for i, result in enumerate(search_results):\n",
        "    tool_trace_content.append(f\"Title: {result.get('title')}, URL: {result.get('url')}\")\n",
        "tool_trace = f\"Search Query: {user_query}\\n\\nResults (Top {len(tool_trace_content)}):\\n\" + \"\\n\".join(tool_trace_content)\n",
        "```\n",
        "\n",
        "This correctly includes the search query and a list of results with \"title, URL\".\n",
        "\n",
        "If `use_tavily` is `True` but no results are found, or an error occurs during search, it handles these cases:\n",
        "\n",
        "```python\n",
        "else:\n",
        "    tool_trace = f\"Search Query: {user_query}\\n\\nNo relevant results found.\"\n",
        "```\n",
        "or\n",
        "```python\n",
        "except Exception as e:\n",
        "    tool_trace = f\"Search Query: {user_query}\\n\\nError during search: {e}\"\n",
        "```\n",
        "\n",
        "If `use_tavily` is `False`, the `tool_trace` is set to:\n",
        "\n",
        "```python\n",
        "else:\n",
        "    tool_trace = \"No external tools used.\"\n",
        "```\n",
        "\n",
        "This construction also aligns with the requirement: \"'search query + results (title, URL) if searched, otherwise 'No external tools used'.\"\n",
        "\n",
        "**Conclusion:** Both `decision_trace` and `tool_trace` are constructed as per the specified requirements within the `run_agent` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb53e3ec"
      },
      "source": [
        "### Review of `run_agent` function - Final Answer Formatting\n",
        "\n",
        "#### System Prompt Analysis:\n",
        "\n",
        "The `run_agent` function defines the `system_prompt` as follows:\n",
        "\n",
        "```python\n",
        "system_prompt = (\n",
        "    \"You are an expert auditor and accountant in the UAE. Your role is to provide helpful, accurate, and clear answers to financial and audit-related questions, adopting a professional tone. \"\n",
        "    \"If you use information from web search results, you MUST cite the source (e.g., [1] Title - URL). \"\n",
        "    \"Explain complex concepts clearly, using relevant audit or accounting analogies where appropriate to enhance understanding. \"\n",
        "    \"Ensure your answers are concise yet comprehensive, addressing all aspects of the user's query. \"\n",
        "    \"Always adhere to UAE-specific regulations and practices when applicable.\"\n",
        ")\n",
        "```\n",
        "\n",
        "This `system_prompt` explicitly addresses all aspects of the `final_answer` formatting requirements:\n",
        "\n",
        "-   **Helpful, accurate, clear answers**: \"Your role is to provide helpful, accurate, and clear answers...\"\n",
        "-   **UAE audit/accounting tone**: \"You are an expert auditor and accountant in the UAE... adopting a professional tone... Always adhere to UAE-specific regulations and practices when applicable.\"\n",
        "-   **Citations if web search used**: \"If you use information from web search results, you MUST cite the source (e.g., [1] Title - URL).\"\n",
        "\n",
        "Additionally, the user message content passed to OpenAI includes the `openai_context` (formatted search results) when `use_tavily` is true, providing the model with the necessary information to generate citations.\n",
        "\n",
        "**Conclusion:** The `system_prompt` effectively guides the OpenAI model to produce a `final_answer` that meets all specified formatting and content requirements, including the UAE audit/accounting tone and citations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87f11f2b"
      },
      "source": [
        "### Review of Gradio Interface - Output Display and Mode Handling\n",
        "\n",
        "#### `run_agent_gradio` Function Analysis:\n",
        "\n",
        "The `run_agent_gradio` function acts as a wrapper, calling the core `run_agent` function and then conditionally formatting its outputs for the Gradio interface:\n",
        "\n",
        "```python\n",
        "def run_agent_gradio(user_query: str, mode: str) -> tuple[str, str, str, str, str]:\n",
        "    # Call the core agent logic\n",
        "    decision_trace, tool_trace, final_answer = run_agent(user_query, mode)\n",
        "\n",
        "    # Prepare outputs for Gradio\n",
        "    output_decision_trace = decision_trace\n",
        "    output_tool_trace = tool_trace\n",
        "    output_final_answer = final_answer\n",
        "    output_user_question = f\"User question: {user_query}\"\n",
        "\n",
        "    # Conditional visibility based on mode\n",
        "    if mode == 'Normal Mode':\n",
        "        return output_user_question, output_final_answer, gr.update(value=None, visible=False), gr.update(value=None, visible=False), gr.update(value=output_final_answer, visible=True)\n",
        "    else: # Teach Mode\n",
        "        return output_user_question, output_final_answer, gr.update(value=output_decision_trace, visible=True), gr.update(value=output_tool_trace, visible=True), gr.update(value=output_final_answer, visible=True)\n",
        "```\n",
        "\n",
        "-   **Output Handling**: It correctly captures `decision_trace`, `tool_trace`, and `final_answer` from `run_agent`.\n",
        "-   **Mode Logic**: It uses an `if/else` block to control the visibility of the trace components based on the `mode` parameter.\n",
        "    -   In 'Normal Mode', `decision_trace_output` and `tool_trace_output` are set to `visible=False` and their values to `None` using `gr.update`. The `final_answer_output` is set to `visible=True`.\n",
        "    -   In 'Teach Mode', `decision_trace_output` and `tool_trace_output` are set to `visible=True` with their respective values, and `final_answer_output` is also `visible=True`.\n",
        "\n",
        "#### Gradio Interface (`demo`) Analysis:\n",
        "\n",
        "The Gradio interface defines the `gr.Textbox` components for displaying the outputs:\n",
        "\n",
        "```python\n",
        "    user_question_output = gr.Textbox(label='User Question', interactive=False, visible=True)\n",
        "    decision_trace_output = gr.Textbox(label='Decision Trace', interactive=False, visible=False, lines=3)\n",
        "    tool_trace_output = gr.Textbox(label='Tool Trace', interactive=False, visible=False, lines=5)\n",
        "    final_answer_output = gr.Textbox(label='Final Answer', interactive=False, visible=True, lines=10)\n",
        "```\n",
        "\n",
        "-   **Initial Visibility**: `decision_trace_output` and `tool_trace_output` are initially set to `visible=False`, which aligns with the 'Normal Mode' default.\n",
        "\n",
        "The `outputs` list passed to the `run_button.click` method correctly maps to these components, ensuring that the return values from `run_agent_gradio` update the intended `gr.Textbox` elements:\n",
        "\n",
        "```python\n",
        "    outputs = [\n",
        "        user_question_output,\n",
        "        final_answer_output,\n",
        "        decision_trace_output,\n",
        "        tool_trace_output,\n",
        "        final_answer_output # Duplicated to handle updates correctly across modes\n",
        "    ]\n",
        "\n",
        "    run_button.click(\n",
        "        fn=run_agent_gradio,\n",
        "        inputs=[query_input, mode_dropdown],\n",
        "        outputs=outputs\n",
        "    )\n",
        "```\n",
        "\n",
        "**Conclusion:** The `run_agent_gradio` function and the Gradio interface are correctly configured to pass and display the `decision_trace`, `tool_trace`, and `final_answer` outputs, adhering to the visibility rules for 'Normal Mode' and 'Teach Mode'. All output formatting requirements are met."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef0a745b"
      },
      "source": [
        "## Add Educational Lab Exercise\n",
        "\n",
        "### Subtask:\n",
        "Include a markdown cell with a mini 'lab exercise' after the agent implementation. This exercise will prompt users to modify the `should_use_tavily` gating rules and observe the agent's behavior, encouraging hands-on learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a1e2db7"
      },
      "source": [
        "## Educational Lab Exercise: Customizing Search Gating Logic\n",
        "\n",
        "This mini-lab exercise is designed to help you understand and experiment with the core decision-making process of our ReACT agent, specifically how it decides whether to perform a web search using Tavily.\n",
        "\n",
        "By modifying the `should_use_tavily` function, you can directly influence the agent's behavior and observe the impact on its 'Decision Trace' and 'Final Answer'. This hands-on experience will deepen your understanding of agent design and tool integration.\n",
        "\n",
        "### Instructions:\n",
        "1.  **Locate the `should_use_tavily` function**: Scroll up in the notebook and find the code cell where the `should_use_tavily` function is defined.\n",
        "2.  **Experiment with Gating Rules**:\n",
        "    *   **Add new `search_keywords`**: Think of specific words or phrases that, when present in a user's query, *always* necessitate a web search. For example, you might add 'price', 'cost', 'review' for product-related queries.\n",
        "    *   **Add new `conceptual_phrases`**: Identify phrases that indicate a general or theoretical question that likely does *not* require an external search. For instance, 'what is the meaning of', 'describe the concept of'.\n",
        "    *   **Modify existing conditions**: Adjust the heuristic conditions, such as the `len(query_lower.split()) > 6` rule, to make it more or less sensitive.\n",
        "    *   **Add entirely new rules**: Consider other factors that might influence the decision, like the presence of numbers or specific entity types (though this might require more advanced NLP).\n",
        "3.  **Re-run the Code Cells**: After making changes to the `should_use_tavily` function, you must re-run its defining cell (the cell where it is implemented) and then re-run the Gradio app launch cell (`demo.launch(share=False)`) for your changes to take effect.\n",
        "4.  **Test Your Changes**: Use the Gradio interface to test various queries, both in 'Normal Mode' and especially in 'Teach Mode' to observe the 'Decision Trace'.\n",
        "    *   **Example Test Queries**:\n",
        "        *   Queries containing your new `search_keywords` (e.g., \"What is the current market price of gold?\")\n",
        "        *   Queries containing your new `conceptual_phrases` (e.g., \"Describe the concept of intangible assets.\")\n",
        "        *   Queries that previously triggered a search but now shouldn't, or vice-versa.\n",
        "\n",
        "Observe how the 'Decision Trace' changes and how the agent's 'Final Answer' adapts based on whether it performs a web search or relies solely on its internal knowledge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34b06513"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a summary that confirms the notebook is complete and ready for execution, covering all aspects of the user's request.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aa41fef"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Comprehensive Notebook Introduction and Setup**: The notebook includes a detailed markdown introduction explaining AI agents, the ReACT paradigm, the role of tools (Tavily for web search), and the concept of a 'Decision Trace'. All necessary Python packages (`openai`, `tavily-python`, `gradio`) are installed, and `OPENAI_API_KEY` and `TAVILY_API_KEY` are securely set with robust error handling.\n",
        "*   **Robust Tavily Search Tool**: A `tavily_search` Python function is implemented to interact with the Tavily API, returning structured search results (title, URL, content) with comprehensive error handling, ensuring reliable web search capabilities.\n",
        "*   **Intelligent Search Gating Logic**: The `should_use_tavily` Python function effectively determines whether a web search is necessary based on the user's query. It uses keywords (e.g., 'latest', 'verify', 'current') and conceptual phrases to make a boolean decision and provides a clear reason, preventing unnecessary API calls.\n",
        "*   **Core ReACT Agent Implementation**: The `run_agent` Python function orchestrates the ReACT paradigm. It integrates the `should_use_tavily` and `tavily_search` functions, uses the OpenAI API (specifically `gpt-4o`) to synthesize a final answer, and meticulously constructs a 'Decision Trace' (search decision and reason) and a 'Tool Trace' (search query and top results, or \"No external tools used\").\n",
        "*   **Professional Output Formatting**: The agent's final answer generation is guided by a system prompt instructing it to adopt a professional UAE audit/accounting tone, provide helpful and accurate answers, and *must* cite sources (e.g., `[1] Title - URL`) if information from web search results is used. Traces are consistently formatted as specified.\n",
        "*   **Interactive Gradio Frontend**: A Gradio interface is successfully constructed, featuring a textbox for user input, a 'Mode' dropdown ('Teach Mode' for full traces, 'Normal Mode' for final answer only), and a 'Clear' button. It dynamically displays 'User question', 'Decision Trace', 'Tool Trace', and 'Final Answer', preloaded with example questions, and runs in Colab with `share=False`.\n",
        "*   **Educational Lab Exercise**: A markdown cell is included, detailing a mini-lab exercise that guides users to modify the `should_use_tavily` gating rules and observe the agent's behavior, fostering hands-on learning and understanding of agent decision-making.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Enhanced Customization and Fine-tuning**: The educational lab exercise highlights the critical role of the `should_use_tavily` function. A next step could involve exposing more parameters or pre-defined profiles within the Gradio interface to allow users to easily toggle or customize the search gating logic without direct code modification, catering to different domain-specific needs.\n",
        "*   **Advanced Tool Integration**: While Tavily is a strong start, expanding the agent's toolkit with other specialized tools (e.g., a PDF parser for internal documents, a financial data API, or a code interpreter) would significantly enhance its capabilities for a wider range of audit and accounting tasks.\n"
      ]
    }
  ]
}