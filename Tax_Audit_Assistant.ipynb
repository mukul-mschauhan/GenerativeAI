{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukul-mschauhan/GenerativeAI/blob/main/Tax_Audit_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core Issue\n",
        "\n",
        "Business Problem\n",
        "\n",
        "Tax auditors and regulatory authorities must continuously interpret and apply a large, evolving body of tax laws, regulations, and official guidance.\n",
        "\n",
        "Today, this work is largely manual and fragmented:\n",
        "\n",
        "* Information is spread across acts, rules, circulars, FAQs, and amendments\n",
        "\n",
        "* Regulatory updates occur frequently and asynchronously\n",
        "\n",
        "* Research is time-consuming and difficult to scale\n",
        "\n",
        "* High risk of missed updates, inconsistent interpretation, and rework\n",
        "\n",
        "* Significant effort spent on finding information instead of analyzing it\n",
        "\n",
        "Core Issue\n",
        "\n",
        "Tax audit research is slow, manual, and inconsistent in an environment of rapidly changing regulations."
      ],
      "metadata": {
        "id": "WBqW40h-NSpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhjhGIqkNNLf",
        "outputId": "ae62140f-28f0-4b66-9496-5c081c173a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Cannot install langchain-community==0.2.16, langchain-tavily==0.1.5, langchain-tavily==0.1.6, langchain-tavily==0.2.0, langchain-tavily==0.2.1, langchain-tavily==0.2.10, langchain-tavily==0.2.11, langchain-tavily==0.2.12, langchain-tavily==0.2.13, langchain-tavily==0.2.14, langchain-tavily==0.2.15, langchain-tavily==0.2.16, langchain-tavily==0.2.2, langchain-tavily==0.2.3, langchain-tavily==0.2.4, langchain-tavily==0.2.5, langchain-tavily==0.2.6, langchain-tavily==0.2.7, langchain-tavily==0.2.8, langchain-tavily==0.2.9 and langchain==0.2.16 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install -U \\\n",
        "  gradio==4.44.0 \\\n",
        "  langchain==0.2.16 \\\n",
        "  langchain-community==0.2.16 \\\n",
        "  langchain-openai==0.1.23 \\\n",
        "  openai==1.42.0 \\\n",
        "  diskcache==5.6.3\\\n",
        "  langchain-tavily\\\n",
        "  langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "OPENAI_BASE_URL = \"https://aibe.mygreatlearning.com/openai/v1\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "JWjKbYqAOcff"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why there is need of Disk Cache?\n",
        "\n",
        "We use diskcache to avoid repeating the same expensive operations—like calling Tavily search and the OpenAI model—when the user runs similar queries multiple times during a session or after a notebook restart. It stores results on disk, so the app becomes faster, less expensive, and more stable, reduces API calls and rate-limit errors, and keeps the demo smooth in Colab where cells may be re-run frequently. That said, it’s not mandatory for correctness—if simplicity is the goal, an in-memory cache can be used instead."
      ],
      "metadata": {
        "id": "vZxGWIIfQTLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diskcache Installation\n",
        "!pip -q install -U diskcache\n",
        "import sys, subprocess, pkgutil\n",
        "\n",
        "print(\"diskcache found:\", pkgutil.find_loader(\"diskcache\") is not None)\n",
        "!pip show diskcache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN3vttThP_4M",
        "outputId": "0d729ff2-d53d-4834-ba88-d35e3b1921c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4184041735.py:5: DeprecationWarning: 'pkgutil.find_loader' is deprecated and slated for removal in Python 3.14; use importlib.util.find_spec() instead\n",
            "  print(\"diskcache found:\", pkgutil.find_loader(\"diskcache\") is not None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diskcache found: True\n",
            "Name: diskcache\n",
            "Version: 5.6.3\n",
            "Summary: Disk Cache -- Disk and file backed persistent cache.\n",
            "Home-page: http://www.grantjenks.com/docs/diskcache/\n",
            "Author: Grant Jenks\n",
            "Author-email: contact@grantjenks.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-tavily langchain-openai langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGPKT5YqQ1vJ",
        "outputId": "ac162303-f0a6-4873-99c9-fb321aa7a283"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core configuration + guardrails"
      ],
      "metadata": {
        "id": "y9Jarth8RZy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, re, hashlib\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "from diskcache import Cache\n",
        "\n",
        "# LangChain Tavily tool (mandatory)\n",
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "\n",
        "# LLM\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "CACHE_DIR = \"/content/tax_agent_cache\"\n",
        "cache = Cache(CACHE_DIR)\n",
        "\n",
        "#DEFAULT_BASE_URL = \"https://api.openai.com/v1\"\n",
        "\n",
        "def now_utc():\n",
        "    return time.strftime(\"%Y-%m-%d %H:%M:%S UTC\", time.gmtime())\n",
        "\n",
        "# Preferred authority domains (heuristic scoring)\n",
        "PREFERRED_DOMAINS = {\n",
        "    \"UAE\": [\"tax.gov.ae\", \"u.ae\", \"mof.gov.ae\", \"uaecabinet.ae\", \"adaa.gov.ae\"],\n",
        "    \"India\": [\"incometax.gov.in\", \"cbic.gov.in\", \"gst.gov.in\", \"indiacode.nic.in\", \"egazette.nic.in\"],\n",
        "    \"US\": [\"irs.gov\", \"treasury.gov\", \"govinfo.gov\", \"ecfr.gov\"],\n",
        "    \"UK\": [\"gov.uk\", \"hmrc.gov.uk\", \"legislation.gov.uk\"],\n",
        "    \"Other\": []}\n",
        "\n",
        "LOW_TRUST_HINTS = [\"medium.com\", \"wordpress\", \"substack\", \"quora.com\", \"reddit.com\"]\n",
        "\n",
        "DISCLAIMER = \"⚠️ **This is NOT legal or tax advice.** Verify with official authority publications.\"\n",
        "\n",
        "# Responsible AI policy (what this assistant MUST do)\n",
        "RESPONSIBLE_AI_BANNER = (\n",
        "    \"⚠️ **Disclaimer:** This is **NOT legal or tax advice**. \"\n",
        "    \"Use this output for audit support only and verify with official authority publications.\\n\"\n",
        ")\n",
        "\n",
        "DISALLOWED = [\n",
        "    \"step-by-step filing instructions\",\n",
        "    \"tax planning / minimization / avoidance strategies\",\n",
        "    \"loophole exploitation guidance\",\n",
        "    \"fabricating laws, sections, penalties, or dates\",\n",
        "]\n",
        "\n",
        "STRICT_OUTPUT_FORMAT = \"\"\"\n",
        "Return the report with these exact sections, in order:\n",
        "\n",
        "A) Applicable Sources\n",
        "B) Key Provisions & Obligations\n",
        "C) Exemptions & Thresholds\n",
        "D) Penalties & Compliance Risks\n",
        "E) Audit Checklist\n",
        "F) Assumptions & Interpretation Limits\n",
        "G) Citations\"\"\"\n",
        "\n",
        "def domain_of(url: str) -> str:\n",
        "    m = re.search(r\"https?://([^/]+)/?\", url)\n",
        "    return (m.group(1).lower() if m else \"\").replace(\"www.\", \"\")\n",
        "\n",
        "def is_preferred(jurisdiction: str, dom: str) -> bool:\n",
        "    prefs = PREFERRED_DOMAINS.get(jurisdiction, [])\n",
        "    return any(dom.endswith(p) for p in prefs) or dom.endswith(\".gov\") or dom.endswith(\".gov.uk\")\n",
        "\n",
        "def low_trust(dom: str) -> bool:\n",
        "    return any(x in dom for x in LOW_TRUST_HINTS)\n",
        "\n",
        "def authority_hint(jurisdiction: str, url: str) -> str:\n",
        "    dom = domain_of(url)\n",
        "    if is_preferred(jurisdiction, dom):\n",
        "        return \"Official / Government / Tax Authority (preferred)\"\n",
        "    if low_trust(dom):\n",
        "        return \"Low-trust web source (downgraded)\"\n",
        "    return \"General web source (use with caution)\"\n",
        "\n",
        "def get_llm() -> ChatOpenAI:\n",
        "    base_url = os.getenv(\"OPENAI_BASE_URL\") or DEFAULT_BASE_URL\n",
        "    return ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0.1,          # stable + audit-friendly\n",
        "        base_url=base_url,\n",
        "        timeout=45,\n",
        "        max_retries=2\n",
        "    )\n",
        "\n",
        "@dataclass\n",
        "class WebHit:\n",
        "    title: str\n",
        "    url: str\n",
        "    snippet: str\n",
        "    domain: str\n",
        "    authority: str\n"
      ],
      "metadata": {
        "id": "hriCxARTPLLN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tavily search + ranking + caching"
      ],
      "metadata": {
        "id": "bD3ogiuaRbgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_search(jurisdiction: str, query: str, max_results: int):\n",
        "    if not query or len(query.strip()) < 10:\n",
        "        raise ValueError(\"Please enter a more detailed audit scenario (>=10 characters).\")\n",
        "    if not jurisdiction:\n",
        "        raise ValueError(\"Please select a jurisdiction.\")\n",
        "\n",
        "    local_tool = TavilySearch(max_results=int(max_results))\n",
        "    payload = local_tool.invoke({\"query\": f\"{jurisdiction} tax law official guidance {query}\"})\n",
        "\n",
        "    results = (payload.get(\"results\", []) or [])\n",
        "\n",
        "    # Rank: govt/official first, then other sites; within each, rank by Tavily score\n",
        "    def sort_key(r):\n",
        "        url = r.get(\"url\", \"\")\n",
        "        dom = domain_of(url)\n",
        "\n",
        "        official_bucket = 0 if is_preferred(jurisdiction, dom) else 1   # 0 = official first\n",
        "        low_trust_penalty = 1 if low_trust(dom) else 0                  # push low-trust later\n",
        "        tavily_score = float(r.get(\"score\") or 0.0)                     # higher is better\n",
        "\n",
        "        return (official_bucket, low_trust_penalty, -tavily_score)\n",
        "\n",
        "    results = sorted(results, key=sort_key)\n",
        "\n",
        "    insufficient_authority = (jurisdiction in [\"UAE\", \"India\", \"US\", \"UK\"]) and not any(\n",
        "        is_preferred(jurisdiction, domain_of(r.get(\"url\", \"\"))) for r in results[:5]\n",
        "    )\n",
        "\n",
        "    return results, insufficient_authority"
      ],
      "metadata": {
        "id": "CjMWbn-vWWH1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_report(jurisdiction: str, query: str, company_context: str, strictness: float, results: list, insufficient_authority: bool):\n",
        "    strict_mode = \"Conservative\" if strictness < 0.5 else \"Broad (still evidence-based)\"\n",
        "\n",
        "    # Build evidence block from Tavily snippets only\n",
        "    sources_block = []\n",
        "    evidence_block = []\n",
        "    for i, r in enumerate(results, start=1):\n",
        "        url = r.get(\"url\",\"\")\n",
        "        title = r.get(\"title\") or url\n",
        "        content = (r.get(\"content\") or \"\").strip()\n",
        "        sources_block.append(\n",
        "            f\"[{i}] {title}\\nURL: {url}\\nAuthority: {authority_hint(jurisdiction, url)}\\nDate: Not found in snippet\\n\"\n",
        "        )\n",
        "        evidence_block.append(f\"Source [{i}] snippet:\\n{content}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an AI Tax Research & Audit Support Assistant for auditors/regulators.\n",
        "\n",
        "Start your answer with:\n",
        "\"{DISCLAIMER}\"\n",
        "Also include: \"Last verified on {now_utc()}\"\n",
        "\n",
        "User Inputs:\n",
        "- Jurisdiction: {jurisdiction}\n",
        "- Strictness: {strict_mode}\n",
        "- Query/Audit Scenario: {query}\n",
        "- Company Context: {company_context}\n",
        "\n",
        "NON-NEGOTIABLE GUARDRAILS:\n",
        "1) Use ONLY the provided snippets as evidence.\n",
        "2) Do NOT invent section numbers, thresholds, penalties, dates, or authority statements.\n",
        "3) If the snippets do not contain enough detail, explicitly say \"Not specified in snippet\" or\n",
        "   \"Insufficient authoritative guidance found\" (especially if insufficient_authority=True).\n",
        "4) Do NOT provide filing instructions or tax planning/avoidance strategies.\n",
        "\n",
        "insufficient_authority = {insufficient_authority}\n",
        "\n",
        "Sources (for citations):\n",
        "{chr(10).join(sources_block)}\n",
        "\n",
        "Evidence (snippets only):\n",
        "{chr(10)+chr(10)}{(chr(10)+chr(10)).join(evidence_block)}\n",
        "\n",
        "Return EXACTLY in this format:\n",
        "{STRICT_OUTPUT_FORMAT}\n",
        "\n",
        "Use inline citations [1], [2] across sections B–F and list them in G) Citations.\n",
        "In F) clearly state limitation: this report is based on search snippets (no full-text retrieval).\n",
        "\"\"\".strip()\n",
        "\n",
        "    return llm.invoke(prompt).content"
      ],
      "metadata": {
        "id": "X9VgkNheWZ2p"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio App (Research + Generate Summary + Export MD)"
      ],
      "metadata": {
        "id": "8upTpgKZcfZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import traceback\n",
        "\n",
        "def ui_research(jurisdiction, query, company_context, strictness, max_sources):\n",
        "    results, insufficient = run_search(jurisdiction, query, int(max_sources))\n",
        "\n",
        "    preview_lines = [f\"{DISCLAIMER}\\n\", f\"Last verified: {now_utc_str()}\\n\"]\n",
        "    if insufficient:\n",
        "        preview_lines.append(\"⚠️ Insufficient authoritative guidance found in top sources; output will be cautious.\\n\")\n",
        "\n",
        "    for i, r in enumerate(results, start=1):\n",
        "        content = r.get(\"content\", \"\") or \"\"\n",
        "        preview_lines.append(\n",
        "            f\"**[{i}] {r.get('title','')}**\\n\"\n",
        "            f\"- {authority_hint(jurisdiction, r.get('url',''))}\\n\"\n",
        "            f\"- {r.get('url','')}\\n\"\n",
        "            f\"- Snippet: {(content[:240] + '…') if len(content)>240 else content}\\n\"\n",
        "        )\n",
        "\n",
        "    state = {\n",
        "        \"jurisdiction\": jurisdiction,\n",
        "        \"query\": query,\n",
        "        \"company_context\": company_context or \"\",\n",
        "        \"strictness\": float(strictness),\n",
        "        \"results\": results,\n",
        "        \"insufficient\": insufficient\n",
        "    }\n",
        "\n",
        "    # Enable generate button only after successful research\n",
        "    btn_update = gr.update(interactive=bool(results))\n",
        "\n",
        "    return state, \"\\n\\n\".join(preview_lines), \"\", \"✅ Research completed. Now click **Generate Audit Summary**.\", \"\", btn_update\n",
        "\n",
        "\n",
        "def ui_generate(state):\n",
        "    try:\n",
        "        if not state or not state.get(\"results\"):\n",
        "            return \"⚠️ No research data found. Please click **Research** first.\", \"⚠️ Missing state/results.\", \"\"\n",
        "\n",
        "        status = \"⏳ Generating audit summary from Tavily snippets…\"\n",
        "\n",
        "        summary = build_report(\n",
        "            jurisdiction=state[\"jurisdiction\"],\n",
        "            query=state[\"query\"],\n",
        "            company_context=state[\"company_context\"],\n",
        "            strictness=state[\"strictness\"],\n",
        "            results=state[\"results\"],\n",
        "            insufficient_authority=state[\"insufficient\"]\n",
        "        )\n",
        "\n",
        "        return summary, \"✅ Summary generated.\", \"\"  # report, status, error\n",
        "\n",
        "    except Exception:\n",
        "        return \"\", \"❌ Failed to generate summary.\", \"```text\\n\" + traceback.format_exc() + \"\\n```\"\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"AI Tax Research & Audit Support Assistant\") as demo:\n",
        "    gr.Markdown(\"## AI Tax Research & Audit Support Assistant (LangChain Tavily + Guardrails)\")\n",
        "    gr.Markdown(DISCLAIMER)\n",
        "\n",
        "    st = gr.State({})\n",
        "\n",
        "    with gr.Row():\n",
        "        jurisdiction = gr.Dropdown([\"UAE\",\"India\",\"US\",\"UK\",\"Other\"], value=\"UAE\", label=\"Jurisdiction\")\n",
        "        max_sources = gr.Slider(3, 10, value=6, step=1, label=\"Max Sources\")\n",
        "\n",
        "    query = gr.Textbox(label=\"Tax Query / Audit Scenario\", lines=3)\n",
        "    company_context = gr.Textbox(label=\"Optional Company Context\", lines=2)\n",
        "    strictness = gr.Slider(0.0, 1.0, value=0.2, step=0.1, label=\"Strictness\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_r = gr.Button(\"Research\", variant=\"primary\")\n",
        "        btn_g = gr.Button(\"Generate Audit Summary\", interactive=False)\n",
        "\n",
        "    preview = gr.Markdown(label=\"Research Preview\")\n",
        "    report = gr.Markdown(label=\"Audit Summary\")\n",
        "\n",
        "    status = gr.Markdown(label=\"Status\")\n",
        "    error_box = gr.Markdown(label=\"Errors (if any)\")\n",
        "\n",
        "    # Research enables Generate (btn_g is output)\n",
        "    btn_r.click(\n",
        "        ui_research,\n",
        "        inputs=[jurisdiction, query, company_context, strictness, max_sources],\n",
        "        outputs=[st, preview, report, status, error_box, btn_g]\n",
        "    )\n",
        "\n",
        "    # Generate fills the report + status + errors\n",
        "    btn_g.click(\n",
        "        ui_generate,\n",
        "        inputs=[st],\n",
        "        outputs=[report, status, error_box]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "V7YbVSu-b0qg",
        "outputId": "f155b7f1-704d-4682-8cd8-bdd088dbf1e7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://15dc4eaff7df8de7bc.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://15dc4eaff7df8de7bc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://15dc4eaff7df8de7bc.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08RlHAf_Ukm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}